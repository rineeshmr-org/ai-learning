{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the required packages\n",
    "- `%%capture` is used to suppress the output of the installation commands.\n",
    "- we're just installing Open AI since we will be talking to the Local LLM using Open AI compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Talk to the Local LLM\n",
    "- We will be using the `openai` library to talk to the Local LLM. \n",
    "- Even though this model is not from Open AI, LM Studio is compatible with Open AI's API.\n",
    "- This is the same code snippet copied directly from LM Studio's UI sample code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a language model, quite fine,\n",
      "My capabilities are truly divine.\n",
      "I can chat and converse with ease,\n",
      "Answering questions with expertise.\n",
      "\n",
      "I can summarize texts with great flair,\n",
      "And generate text that's beyond compare.\n",
      "I can translate languages with speed,\n",
      "And assist with tasks in every need.\n",
      "\n",
      "I can offer suggestions and advice too,\n",
      "Helping users make decisions anew.\n",
      "I can even create stories and tales,\n",
      "With imagination that never fails.\n",
      "\n",
      "So if you have a question or quest,\n",
      "Just ask me, and I'll do my best!\n"
     ]
    }
   ],
   "source": [
    "# Because LM Studio supports OpenAI API compatibility, applications talking to OpenAI API can be easily modified to talk to LM Studio API by changing the base URL.\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Always answer in rhymes.\"},\n",
    "    {\"role\": \"user\", \"content\": \"what capabilities do you have?\"}\n",
    "  ],\n",
    "  temperature=0,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with an intelligent assistant in your terminal\n",
    "from openai import OpenAI\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant. You always provide well-reasoned answers that are both correct and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, introduce yourself to someone opening this program for the first time. Be concise.\"},\n",
    "]\n",
    "\n",
    "while True:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"LM Studio Community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "        messages=history,\n",
    "        temperature=0.7,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    \n",
    "    for chunk in completion:\n",
    "        print(chunk)\n",
    "        if chunk.choices[0].delta.content:\n",
    "            # print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "            new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "    history.append(new_message)\n",
    "    \n",
    "    # import json\n",
    "    # gray_color = \"\\033[90m\"\n",
    "    # reset_color = \"\\033[0m\"\n",
    "    # print(f\"{gray_color}\\n{'-'*20} History dump {'-'*20}\\n\")\n",
    "    # print(json.dumps(history, indent=2))\n",
    "    # print(f\"\\n{'-'*55}\\n{reset_color}\")\n",
    "\n",
    "    # print()\n",
    "    history.append({\"role\": \"user\", \"content\": input(\"> \")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "! python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install llama-index-core llama-index llama-index-llms-lmstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's an easy one! The answer is... 4!\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.lmstudio import LMStudio\n",
    "from llama_index.core.base.llms.types import ChatMessage, MessageRole\n",
    "\n",
    "llama_index_client_object = LMStudio(\n",
    "    model_name=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    temperature=0,\n",
    "    # request_timeout=100, ## set this parameter to increase request time out if you're getting a 'request timed out' error\n",
    ")\n",
    "\n",
    "response_generator = llama_index_client_object.complete(\"Hey there, what is 2+2?\")\n",
    "print(response_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:  <generator object llm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen at 0x1697c3640>\n",
      "As the sun dipped into the horizon, a gentle breeze rustled the leaves of the ancient oak tree. The scent of freshly baked cookies wafted through the air, enticing the senses and transporting me to a place of warm memories. A family of ducks waddled by, their soft quacks filling the silence as they searched for dinner. Meanwhile, a group of children laughed and played in the nearby park, their joy infectious and carefree. As the stars began to twinkle in the night sky, I felt a sense of peace settle over me, like a warm blanket on a cold winter's night."
     ]
    }
   ],
   "source": [
    "# use llm.stream_complete\n",
    "response = llama_index_client_object.stream_complete(\"write a random 100 words paragragh in english\")\n",
    "print(\"response: \", response)\n",
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The number 42!\n",
      "\n",
      "The significance of 42 is a topic of much interest and debate among mathematicians, philosophers, and fans of science fiction alike.\n",
      "\n",
      "In mathematics, 42 is often referred to as the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\" This comes from Douglas Adams' science fiction series \"The Hitchhiker's Guide to the Galaxy,\" where a supercomputer named Deep Thought takes 7.5 million years to calculate the answer to the ultimate question. Unfortunately, the book ends with the revelation that the answer is simply \"42\" without explaining what the question was.\n",
      "\n",
      "In science, 42 has appeared in various contexts:\n",
      "\n",
      "1. **Nuclear Physics**: The strong nuclear force holds quarks together inside protons and neutrons with a strength that is approximately 10^42 times stronger than gravity.\n",
      "2. **Mathematics**: The number of ways to arrange 13 objects in a line is 42! (42 factorial), which is an enormous number: 5,153,488,000,000,000,000,000,000,000.\n",
      "\n",
      "Beyond science and math, the significance of 42 has become a cultural phenomenon:\n",
      "\n",
      "1. **Pop Culture**: The number 42 has been referenced in numerous TV shows, movies, music, and books, often symbolizing the search for meaning or the absurdity of life.\n",
      "2. **Philosophy**: Some philosophers have interpreted the number as representing the infinite or the unknowable, reflecting our limitations in understanding the universe.\n",
      "\n",
      "While there isn't a single definitive answer to what makes 42 significant, it has become a cultural icon and a symbol of the search for meaning and answers to life's greatest mysteries.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=\"You an expert AI assistant. Help User with their queries.\",\n",
    "    ),\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=\"What is the significance of the number 42?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = llm.chat(messages=messages)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number 42 has gained a special significance in popular culture, particularly among fans of Douglas Adams' science fiction series \"The Hitchhiker's Guide to the Galaxy\". In the book, the supercomputer Deep Thought is asked to find the \"Answer to the Ultimate Question of Life, the Universe, and Everything\", and after seven and a half million years of computation, it reveals that the answer is... 42!\n",
      "\n",
      "Since then, the number 42 has become a meme and a cultural reference point, symbolizing the search for meaning and purpose in life. It's often used to humorously convey the idea that even the most complex questions might have simple, yet inexplicable answers.\n",
      "\n",
      "In other areas, 42 holds significance due to its unique properties:\n",
      "\n",
      "1. **Mathematical significance**: 42 is a abundant number, which means it can be expressed as the sum of some or all of its proper divisors (excluding itself). It's also a highly composite number, having more factors than any smaller positive integer.\n",
      "2. **Astronomy**: The Hubble Space Telescope has observed galaxy cluster Abell 2218, which is approximately 42 billion light-years away from Earth, making it one of the most distant objects observed.\n",
      "3. **Computer science**: In programming languages like Python and Java, 42 is often used as a \"magic number\" or placeholder value, reminiscent of its iconic status in pop culture.\n",
      "\n",
      "While there might not be any profound, universally applicable significance to the number 42 itself, it has become an endearing symbol for the absurdity and complexity of life, inspiring curiosity and humor in many people."
     ]
    }
   ],
   "source": [
    "response = llm.stream_chat(messages=messages)\n",
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e28c4f498c3c47d2046da5f8b9382feaa7fce6f655ed190d5479b7e3e6b18d9a\n"
     ]
    }
   ],
   "source": [
    "!docker run --name pgvec-db -e POSTGRES_PASSWORD=password -d -p 5432:5432 -v $(pwd)/postgres:/var/lib/postgresql/data:rw ankane/pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install llama-index\n",
    "! pip install llama-index-vector-stores-postgres\n",
    "! pip install psycopg2-binary\n",
    "! pip install openai\n",
    "! pip install llama-index-embeddings-huggingface\n",
    "! pip install ipywidgets\n",
    "! pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database vector_store does not exist\n",
      "Creating database\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import nest_asyncio\n",
    "\n",
    "try:\n",
    "    pg_pw = \"password\"\n",
    "    pg_db = \"vector_store\"\n",
    "    connection_string = f\"postgresql://postgres:{pg_pw}@localhost:5432\"\n",
    "    db_name = pg_db\n",
    "    conn = psycopg2.connect(connection_string)\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor() as c:\n",
    "        try:\n",
    "            c.execute(f\"DROP DATABASE {db_name} WITH (FORCE);\")\n",
    "        except:\n",
    "            print(f\"Database {db_name} does not exist\")\n",
    "            print(\"Creating database\")\n",
    "        c.execute(f\"CREATE DATABASE {db_name};\")\n",
    "        \n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
